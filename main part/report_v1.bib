
@inproceedings{abbeel_discriminative_2005,
	title = {Discriminative Training of Kalman Filters},
	doi = {10.15607/RSS.2005.I.038},
	abstract = {Kalman filters are a workhorse of robotics and are routinely used in state-estimation problems. However, their performance critically depends on a large number of modeling parameters which can be very difficult to obtain, and are often set via significant manual tweaking and at a great cost of engineering time. In this paper, we propose a method for automatically learning the noise parameters of a Kalman filter. We also demonstrate on a commercial wheeled rover that our Kalman filter's learned noise covariance parameters—obtained quickly and fully automatically—significantly outperform an earlier, carefully and laboriously hand-designed one.},
	pages = {289--296},
	author = {Abbeel, Pieter and Coates, Adam and Montemerlo, Michael and Ng, Andrew and Thrun, Sebastian},
	date = {2005-06-08},
	file = {Texte intégral:/Users/randolf/Zotero/storage/YURESLQI/Abbeel et al. - 2005 - Discriminative Training of Kalman Filters.pdf:application/pdf},
}

@software{choi_awesome_2023,
	title = {Awesome Sensor Logger},
	rights = {{MIT}},
	url = {https://github.com/tszheichoi/awesome-sensor-logger},
	abstract = {Collection of tools, resources and sample code to use alongside the Sensor Logger app},
	author = {Choi, Kelvin},
	urldate = {2023-09-29},
	date = {2023-09-27},
	note = {original-date: 2022-06-10T17:36:07Z},
}

@inproceedings{santos_indoor_2015,
	title = {Indoor waypoint {UAV} navigation using a {RGB}-D system},
	url = {https://ieeexplore.ieee.org/document/7440994},
	doi = {10.1109/RED-UAS.2015.7440994},
	abstract = {This paper presents a method for estimating the orientation and position of an unmanned aerial vehicle ({UAV}), through processing information provided by a {RGB}-D sensor and an inertial measurement unit ({IMU}) in order to inspect predefined points in an indoor environment. A fusion filter is implemented to correct the existing drift position and orientation errors on a commercial {AR}.Drone quadrotor model. In addition, it was adopted a {PD} controller to position the {UAV} in such points with predetermined orientations. Experiments involving abrupt maneuvers to induce errors in the estimation of position and orientation were carried out, to check the effectiveness of the developed 3D data capture system and the designed controller. Results show the success of the new approach integrating a data fusion system to estimate {UAV} position and orientation.},
	eventtitle = {2015 Workshop on Research, Education and Development of Unmanned Aerial Systems ({RED}-{UAS})},
	pages = {84--91},
	booktitle = {2015 Workshop on Research, Education and Development of Unmanned Aerial Systems ({RED}-{UAS})},
	author = {Santos, Milton C. P. and Sarcinelli-Filho, Mário and Carelli, Ricardo},
	urldate = {2023-09-30},
	date = {2015-11},
	file = {IEEE Xplore Abstract Record:/Users/randolf/Zotero/storage/S6JV3I6J/7440994.html:text/html;IEEE Xplore Full Text PDF:/Users/randolf/Zotero/storage/7KNACZRW/Santos et al. - 2015 - Indoor waypoint UAV navigation using a RGB-D syste.pdf:application/pdf},
}

@inproceedings{tsai_novel_2012,
	title = {A novel image-based object orientation estimation algorithm for robotic manipulator applications},
	url = {https://ieeexplore.ieee.org/document/6473496},
	doi = {10.1109/ISPACS.2012.6473496},
	abstract = {In many robotic manipulator applications, the robot manipulator usually requires knowing the orientation of an object-of-interest to perform grasp planning. This paper presents a novel image-based object orientation estimation algorithm that efficiently and accurately estimates the orientation of a geometric object from vision information only. First, a boundary-point set is defined from the boundary of a geometric object in a segmented binary image. Next, a new objective function is proposed to evaluate the maximum projection length of the boundary-point set onto a closed set with respect to an orientation angle. Finally, the orientation information of the geometric object is estimated via a one-dimensional minimization process. Simulation and experimental results show that the proposed method is able to provide accurate estimates for geometric objects with maximum absolute error less than 0.35°, which is enough to satisfy the requirement on robot grasping control tasks.},
	eventtitle = {2012 International Symposium on Intelligent Signal Processing and Communications Systems},
	pages = {280--284},
	booktitle = {2012 International Symposium on Intelligent Signal Processing and Communications Systems},
	author = {Tsai, Chi-Yi and Wong, Ching-Chang and Liu, Tsung-Yen and Tsao, An-Hung},
	urldate = {2023-09-30},
	date = {2012-11},
	file = {IEEE Xplore Abstract Record:/Users/randolf/Zotero/storage/W6L4CNHF/6473496.html:text/html;IEEE Xplore Full Text PDF:/Users/randolf/Zotero/storage/J7YZSJCB/Tsai et al. - 2012 - A novel image-based object orientation estimation .pdf:application/pdf},
}

@inproceedings{ogata_robust_2019,
	title = {A Robust Position and Posture Measurement System Using Visual Markers and an Inertia Measurement Unit},
	url = {https://ieeexplore.ieee.org/document/8967887},
	doi = {10.1109/IROS40897.2019.8967887},
	abstract = {Automatic control of mobile robots and robot arms requires techniques for estimating the position and orientation of objects with high accuracy and robustness. Although methods using markers or machine learning have been developed, general-purpose and highly accurate estimations have not been realized. Our team developed a high-accuracy visual marker “{LentiMark}” for high-accuracy estimations of position and posture, but data are lost when the camera cannot obtain marker images. We therefore developed the Marker-{IMU} system for integrating visual markers with an inertia measurement unit ({IMU}). When cameras cannot acquire the image of a visual marker, any missing data are restored from {IMU} data. However, when calculating positions from acceleration sensor values, sensor error increases estimation error. Therefore, we developed a method for error correction using measurements from before and after the missing data. Evaluation experiments confirm that missing data can be estimated using the proposed method.},
	eventtitle = {2019 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
	pages = {7497--7502},
	booktitle = {2019 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
	author = {Ogata, Kunihiro and Tanaka, Hideyuki and Matsumoto, Yoshio},
	urldate = {2023-09-30},
	date = {2019-11},
	note = {{ISSN}: 2153-0866},
	file = {IEEE Xplore Abstract Record:/Users/randolf/Zotero/storage/8JPMMAWC/8967887.html:text/html;IEEE Xplore Full Text PDF:/Users/randolf/Zotero/storage/ICMKECTM/Ogata et al. - 2019 - A Robust Position and Posture Measurement System U.pdf:application/pdf},
}

@inproceedings{lai_real-time_2015,
	title = {Real-time indoor positioning system based on {RFID} Heron-bilateration location estimation and {IMU} angular-driven navigation reckoning},
	url = {https://ieeexplore.ieee.org/document/7274586},
	doi = {10.1109/ICCIS.2015.7274586},
	abstract = {A real-time indoor positioning system is developed, featuring 2 novel perfectly complementary positioning methods: 1) {RFID} Heron-bilateration location estimation, based on external {RFID} infrastructure, and 2) {IMU} angular-driven navigation reckoning, based on internal {IMU} module. At first, 2 or multiples of 2 active {RFID} tags as infrastructure landmarks are deployed along surrounding walls in a single indoor space or room. After the infrastructure landmarks are set up, the handheld indoor positioning device begins to connect to the Bluetooth-based {RFID} reader by pairing with Bluetooth {ID} of the {RFID} reader. Then, on the screen of the handheld indoor positioning device, red landmarks on the 2D indoor map represents pre-deployed active {RFID} tags. When moving, the targeted handheld indoor positioning device keeps estimating the relative location through external {RFID} infrastructure and keeps reckoning the inertial navigation through internal {IMU} module. Experimental results show these two proposed positioning methods, {RFID} Heron-bilateration location estimation and {IMU} angular-driven navigation reckoning, can cooperatively improve the accuracy and reliability of indoor positioning system further. Finally, the screen of the handheld indoor positioning device can show the location and orientation indications of the targeted user on the 2D indoor map accurately and immediately.},
	eventtitle = {2015 {IEEE} 7th International Conference on Cybernetics and Intelligent Systems ({CIS}) and {IEEE} Conference on Robotics, Automation and Mechatronics ({RAM})},
	pages = {276--281},
	booktitle = {2015 {IEEE} 7th International Conference on Cybernetics and Intelligent Systems ({CIS}) and {IEEE} Conference on Robotics, Automation and Mechatronics ({RAM})},
	author = {Lai, Zu-Hao and Ho, Chian C.},
	urldate = {2023-09-30},
	date = {2015-07},
	note = {{ISSN}: 2326-8239},
	file = {IEEE Xplore Abstract Record:/Users/randolf/Zotero/storage/VICERCY5/7274586.html:text/html;IEEE Xplore Full Text PDF:/Users/randolf/Zotero/storage/PAFZPM2B/Lai et Ho - 2015 - Real-time indoor positioning system based on RFID .pdf:application/pdf},
}

@online{noauthor_figure_nodate,
	title = {Figure 10: (a) Pitch, yaw and roll angles of an aircraft with body...},
	url = {https://www.researchgate.net/figure/a-Pitch-yaw-and-roll-angles-of-an-aircraft-with-body-orientation-O-u-v-original_fig7_348803228},
	shorttitle = {Figure 10},
	abstract = {Download scientific diagram {\textbar} (a) Pitch, yaw and roll angles of an aircraft with body orientation [Ω, u, v] (original picture released under the Creative Commons {CC}0 licence by https://pixabay.com). (b) Construction of the roll angle of A = [Ω, u, v], where the vectors Ω, u and v are respectively in red, green and blue. The local frame is (Ω, p(Ω), q(Ω)) where p(Ω) and q(Ω)) and the plane generated by them are in purple. u and v belong to this plane. ζ is the angle between p(Ω) and u. from publication: Bulk topological states in a new collective dynamics model {\textbar} In this paper, we demonstrate the existence of topological states in a new collective dynamics model. This individual-based model ({IBM}) describes self-propelled rigid bodies moving with constant speed and adjusting their rigid-body attitude to that of their neighbors. In... {\textbar} Topology, Dynamic Modeling and Bulk {\textbar} {ResearchGate}, the professional network for scientists.},
	titleaddon = {{ResearchGate}},
	urldate = {2023-09-30},
	langid = {english},
	file = {Snapshot:/Users/randolf/Zotero/storage/EUJKZSV8/a-Pitch-yaw-and-roll-angles-of-an-aircraft-with-body-orientation-O-u-v-original_fig7_348803228.html:text/html},
}

@inproceedings{severin_head_2020,
	title = {Head Posture Monitor Based On 3 {IMU} Sensors: Consideration Toward Healthcare Application},
	url = {https://ieeexplore.ieee.org/document/9280106},
	doi = {10.1109/EHB50910.2020.9280106},
	shorttitle = {Head Posture Monitor Based On 3 {IMU} Sensors},
	abstract = {In this research is presented a new head posture recognition system based on three inertial sensors. The developed device was evaluated through a real-time monitor system that includes 3 risk posture factors. The proposed system provides audio feedback in the case when the posture of the human subject is out of the established threshold. This application has the potential to provide prevention and correction of the chronic bad posture that causing neck pain, back pain, etc. During the experiment, all processing steps were done on the Node {MCU} development board. The experimental results show the abilities of the proposed system to distinguish between the poor and the correct head posture successfully. The principal focus of this article was to design and construct a wearable device that detects and corrects the poor posture of the head through continuous use by the office workers.},
	eventtitle = {2020 International Conference on e-Health and Bioengineering ({EHB})},
	pages = {1--4},
	booktitle = {2020 International Conference on e-Health and Bioengineering ({EHB})},
	author = {Severin, Ionut-Cristian},
	urldate = {2023-09-30},
	date = {2020-10},
	note = {{ISSN}: 2575-5145},
	file = {IEEE Xplore Abstract Record:/Users/randolf/Zotero/storage/67CBUAV9/9280106.html:text/html;IEEE Xplore Full Text PDF:/Users/randolf/Zotero/storage/VAKPFUAB/Severin - 2020 - Head Posture Monitor Based On 3 IMU Sensors Consi.pdf:application/pdf},
}

@inproceedings{dai_navigation_2019,
	title = {Navigation of Simultaneous Localization and Mapping by Fusing {RGB}-D Camera and {IMU} on {UAV}},
	url = {https://ieeexplore.ieee.org/document/9213339},
	doi = {10.1109/SAFEPROCESS45799.2019.9213339},
	abstract = {Simultaneous localization and mapping ({SLAM}) is one of the key components of the navigation system of unmanned aerial vehicles ({UAVs}). In this paper, a novel system that enables a {UAV} to navigation in a {GPS}-denied environment with an {RGB}-D (Red, Green, Blue, and Depth) camera and Inertial Measurement Unit ({IMU}) is presented. Such a system is realized via a host computer on a {UAV}, in which the {IMU} information read from the flight controller and the image information read from the {RGB}-D camera are fused using extended Kalman filter ({EKF}). Experiments are designed to test the feasibility of the proposed navigation scheme. Accurate assessment of our idea shows a good response when rapidly moving and rotating the {UAV}.},
	eventtitle = {2019 {CAA} Symposium on Fault Detection, Supervision and Safety for Technical Processes ({SAFEPROCESS})},
	pages = {6--11},
	booktitle = {2019 {CAA} Symposium on Fault Detection, Supervision and Safety for Technical Processes ({SAFEPROCESS})},
	author = {Dai, Xi and Mao, Yuxin and Huang, Tianpeng and Li, Binbin and Huang, Deqing},
	urldate = {2023-09-30},
	date = {2019-07},
	file = {IEEE Xplore Abstract Record:/Users/randolf/Zotero/storage/2YBQ4FSD/9213339.html:text/html;IEEE Xplore Full Text PDF:/Users/randolf/Zotero/storage/94J63LA7/Dai et al. - 2019 - Navigation of Simultaneous Localization and Mappin.pdf:application/pdf},
}
